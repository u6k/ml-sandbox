{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learn.9.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/u6k/ml-sandbox/blob/master/learn_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPj8ZzVI69E7",
        "colab_type": "text"
      },
      "source": [
        "未来株価を確実に取得できた場合、強化学習で効果的な利益を得られるか？それができないなら、未来株価を予測しても意味がないことになる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euO8AXq-b-TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0MjwqCERNyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install chainerrl comet_ml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi_9hBd0XMcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from comet_ml import Experiment\n",
        "\n",
        "experiment = Experiment(api_key=COMET_ML_API_KEY, project_name=\"learn-stocks.9\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMM9MGwZcF5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CSVを読み込む\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_csv = pd.read_csv(\"drive/My Drive/projects/ml_data/stocks/stock_prices.20190523.csv\")\n",
        "df_csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGxc2V0R2of_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df = df_csv.copy()\n",
        "\n",
        "df = df.query(\"ticker_symbol == '7974'\").copy()\n",
        "df = df[[\"date\", \"opening_price\", \"high_price\", \"low_price\", \"close_price\", \"turnover\", \"adjustment_value\"]]\n",
        "df = df.sort_values(\"date\")\n",
        "df = df.drop_duplicates()\n",
        "df = df.assign(id=np.arange(len(df)))\n",
        "df = df.set_index(\"id\")\n",
        "\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP82V22o7Jdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.preprocessing as sp\n",
        "\n",
        "df_input = df[-600:].copy()\n",
        "\n",
        "price = df_input[\"opening_price\"].values\n",
        "price = np.append(price, df_input[\"close_price\"].values)\n",
        "price = np.array(price).reshape(len(price), 1)\n",
        "\n",
        "scaler = sp.MinMaxScaler()\n",
        "scaler.fit(price)\n",
        "\n",
        "opening_price = df_input[\"opening_price\"].values\n",
        "opening_price = np.array(opening_price).reshape(len(opening_price), 1)\n",
        "df_input[\"scaled_opening_price\"] = scaler.transform(opening_price)\n",
        "\n",
        "close_price = df_input[\"close_price\"].values\n",
        "close_price = np.array(close_price).reshape(len(close_price), 1)\n",
        "df_input[\"scaled_close_price\"] = scaler.transform(close_price)\n",
        "\n",
        "df_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd8GIgeLCmv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "open_x, open_y, close_x, close_y = [], [], [], []\n",
        "\n",
        "INPUT_LEN = 20\n",
        "\n",
        "for row in range(len(df_input) - INPUT_LEN):\n",
        "  open_x.append(df_input[\"scaled_opening_price\"][row:row+INPUT_LEN].values)\n",
        "  open_y.append(df_input[\"scaled_opening_price\"][row+INPUT_LEN:row+INPUT_LEN+1].values)\n",
        "  close_x.append(df_input[\"scaled_close_price\"][row:row+INPUT_LEN].values)\n",
        "  close_y.append(df_input[\"scaled_close_price\"][row+INPUT_LEN:row+INPUT_LEN+1].values)\n",
        "\n",
        "open_x = np.array(open_x).reshape(len(open_x), INPUT_LEN, 1)\n",
        "open_y = np.array(open_y).reshape(len(open_y), 1)\n",
        "close_x = np.array(close_x).reshape(len(close_x), INPUT_LEN, 1)\n",
        "close_y = np.array(close_y).reshape(len(close_y), 1)\n",
        "\n",
        "print(\"*** open_x ***\")\n",
        "print(open_x)\n",
        "print(\"*** open_y ***\")\n",
        "print(open_y)\n",
        "print(\"*** close_x ***\")\n",
        "print(close_x)\n",
        "print(\"*** close_y ***\")\n",
        "print(close_y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1DRuikRD7sP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "length_of_sequence = INPUT_LEN\n",
        "in_out_neurons = 1\n",
        "n_hidden = 300\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "\n",
        "open_model = Sequential()\n",
        "open_model.add(LSTM(n_hidden,\n",
        "                    batch_input_shape=(None, length_of_sequence, in_out_neurons),\n",
        "                    return_sequences=False))\n",
        "open_model.add(Dense(in_out_neurons))\n",
        "open_model.add(Activation(\"linear\"))\n",
        "open_model.compile(loss=\"mean_squared_error\", optimizer=Adam(lr=0.001))\n",
        "\n",
        "open_history = open_model.fit(open_x,\n",
        "                              open_y,\n",
        "                              batch_size=batch_size,\n",
        "                              epochs=epochs,\n",
        "                              validation_split=0.2,\n",
        "                              callbacks=[EarlyStopping(patience=10, verbose=1)])\n",
        "\n",
        "close_model = Sequential()\n",
        "close_model.add(LSTM(n_hidden,\n",
        "                     batch_input_shape=(None, length_of_sequence, in_out_neurons),\n",
        "                     return_sequences=False))\n",
        "close_model.add(Dense(in_out_neurons))\n",
        "close_model.add(Activation(\"linear\"))\n",
        "close_model.compile(loss=\"mean_squared_error\", optimizer=Adam(lr=0.001))\n",
        "\n",
        "close_history = close_model.fit(close_x,\n",
        "                                close_y,\n",
        "                                batch_size=batch_size,\n",
        "                                epochs=epochs,\n",
        "                                validation_split=0.2,\n",
        "                                callbacks=[EarlyStopping(patience=10, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KErs7k3AE-Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = open_history.history[\"loss\"]\n",
        "val_loss = open_history.history[\"val_loss\"]\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYI712fvFDmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = close_history.history[\"loss\"]\n",
        "val_loss = close_history.history[\"val_loss\"]\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIzA86JyFcEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx in df_input[: -INPUT_LEN].index:\n",
        "  print(str(idx))\n",
        "  result_open_price, result_close_price = [], []\n",
        "  open_price_subset = [df_input.at[idx+i, \"scaled_opening_price\"] for i in range(INPUT_LEN)]\n",
        "  close_price_subset = [df_input.at[idx+i, \"scaled_close_price\"] for i in range(INPUT_LEN)]\n",
        "  \n",
        "  for i in range(INPUT_LEN):\n",
        "    future = open_price_subset[i: INPUT_LEN]\n",
        "    future = np.append(future, result_open_price)\n",
        "    future = np.array(future).reshape(1, INPUT_LEN, 1)\n",
        "    \n",
        "    result = open_model.predict(future)\n",
        "    \n",
        "    result_open_price = np.append(result_open_price, result)\n",
        "    \n",
        "    future = close_price_subset[i: INPUT_LEN]\n",
        "    future = np.append(future, result_close_price)\n",
        "    future = np.array(future).reshape(1, INPUT_LEN, 1)\n",
        "    \n",
        "    result = close_model.predict(future)\n",
        "    \n",
        "    result_close_price = np.append(result_close_price, result)\n",
        "  \n",
        "  for i in range(INPUT_LEN):\n",
        "    df_input.at[idx+INPUT_LEN-1, \"predict_opening_price_\"+str(i)] = result_open_price[i]\n",
        "    df_input.at[idx+INPUT_LEN-1, \"predict_close_price_\"+str(i)] = result_close_price[i]\n",
        "\n",
        "df_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qas6MlyNtEMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tmp = pd.DataFrame({\"input\":df_input[\"scaled_opening_price\"], \"predict\":0.})\n",
        "for i in range(20):\n",
        "  df_tmp.at[8000+i, \"predict\"] = df_input.at[7999+i, \"predict_opening_price_\"+str(i)]\n",
        "\n",
        "df_tmp[-50:].plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltuX0o0sH8h1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_input[\"scaled_opening_price\"].plot()\n",
        "df_input[\"predict_opening_price_1\"].plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oqOE7JKs7C0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_input[\"scaled_close_price\"].plot()\n",
        "df_input[\"predict_close_price_1\"].plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTxEKL7tUvyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import gym\n",
        "import gym.spaces\n",
        "import numpy as np\n",
        "\n",
        "class LearnEnv():\n",
        "  def __init__(self, df, start_id, end_id):\n",
        "    self.DF = df_input.copy()\n",
        "    self.START_ID = start_id\n",
        "    self.END_ID = end_id\n",
        "\n",
        "    self.reset()\n",
        "    \n",
        "    self.data_len = self.END_ID - self.START_ID\n",
        "    self.action_size = 2 # 0...何もしない、1...購入or売却\n",
        "    self.observation_size = len(self.observe())\n",
        "    \n",
        "  def reset(self):\n",
        "    self.total_reward = 0.0\n",
        "    self.funds = 0.0\n",
        "    self.current_id = self.START_ID\n",
        "    self.buy_price = 0.0\n",
        "    self.predict_buy_price = 0.0\n",
        "    self.done = False\n",
        "    self.win = 0\n",
        "    self.lose = 0\n",
        "    \n",
        "    self.df_action = self.DF.copy()\n",
        "    self.df_action = self.df_action.assign(reward=0.)\n",
        "    self.df_action = self.df_action.assign(funds=0.)\n",
        "    self.df_action = self.df_action.assign(buy=0)\n",
        "    self.df_action = self.df_action.assign(sell=0)\n",
        "    self.df_action = self.df_action.assign(win=0)\n",
        "    self.df_action = self.df_action.assign(lose=0)\n",
        "    \n",
        "    return self.observe()\n",
        "    \n",
        "  def step(self, action):\n",
        "    if action == 0:\n",
        "      reward = 0.0\n",
        "    elif self.buy_price == 0.0:\n",
        "      # buy\n",
        "      self.buy_price = self.df_action.at[self.current_id, \"scaled_opening_price\"]\n",
        "      self.predict_buy_price = self.df_action.at[self.current_id-1, \"predict_opening_price_1\"]\n",
        "      self.funds -= self.buy_price\n",
        "      reward = 0.0\n",
        "      \n",
        "      self.df_action.at[self.current_id, \"buy\"] = 1\n",
        "    elif self.buy_price != 0.0:\n",
        "      # sell\n",
        "      sell_price = self.df_action.at[self.current_id, \"scaled_close_price\"]\n",
        "      self.funds += sell_price\n",
        "      reward = sell_price - self.buy_price\n",
        "      self.total_reward += reward\n",
        "      self.buy_price = 0.0\n",
        "      self.predict_buy_price = 0.0\n",
        "      \n",
        "      if reward > 0:\n",
        "        self.win += 1\n",
        "      else:\n",
        "        self.lose += 1\n",
        "      \n",
        "      self.df_action.at[self.current_id, \"sell\"] = 1\n",
        "    \n",
        "    self.df_action.at[self.current_id, \"reward\"] = self.total_reward\n",
        "    self.df_action.at[self.current_id, \"funds\"] = self.funds\n",
        "    self.df_action.at[self.current_id, \"win\"] = self.win\n",
        "    self.df_action.at[self.current_id, \"lose\"] = self.lose\n",
        "    \n",
        "    self.current_id += 1\n",
        "    if self.current_id >= self.END_ID:\n",
        "      self.done = True\n",
        "    \n",
        "    return self.observe(), reward, self.done, {}\n",
        "  \n",
        "  def render(self):\n",
        "    print(self.df_action.loc[self.current_id-1])\n",
        "  \n",
        "  def observe(self):\n",
        "    obs = np.array(\n",
        "        [self.df_action.at[self.current_id - i, \"opening_price\"] for i in range(1, 4)],\n",
        "        dtype=np.float32\n",
        "    )\n",
        "    obs = np.append(obs, np.array(\n",
        "        [self.df_action.at[self.current_id - i, \"predict_opening_price_\"+str(i)] for i in range(0, 3)],\n",
        "        dtype=np.float32\n",
        "    ))\n",
        "    obs = np.append(obs, np.array(\n",
        "        [self.df_action.at[self.current_id - i, \"close_price\"] for i in range(1, 4)],\n",
        "        dtype=np.float32\n",
        "    ))\n",
        "    obs = np.append(obs, np.array(\n",
        "        [self.df_action.at[self.current_id - i, \"predict_close_price_\"+str(i)] for i in range(0, 3)],\n",
        "        dtype=np.float32\n",
        "    ))\n",
        "    obs = np.append(obs, np.array(self.buy_price, dtype=np.float32))\n",
        "    obs = np.append(obs, np.array(self.predict_buy_price, dtype=np.float32))\n",
        "\n",
        "    return obs\n",
        "  \n",
        "  def random_action(self):\n",
        "    return np.random.randint(0, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu2YTLxbhTm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = LearnEnv(df_input, 8036-250, 8036)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk_T4mcEfXsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer\n",
        "import chainerrl\n",
        "\n",
        "hyper_params = {\n",
        "    \"n_hidden_layers\": 3,\n",
        "    \"obs_size\": env.observation_size,\n",
        "    \"n_actions\": env.action_size,\n",
        "    \"n_hidden_channels\": env.observation_size * env.action_size,\n",
        "    \"adam_eps\": 1e-2,\n",
        "    \"gamma\": 0.95,\n",
        "    \"start_epsilon\": 1.0,\n",
        "    \"end_epsilon\": 0.3,\n",
        "    \"decay_steps\": 200 * env.data_len,\n",
        "    \"replay_buffer_capacity\": 10 ** 6,\n",
        "    \"ddqn_replay_start_size\": 500,\n",
        "    \"ddqn_update_interval\": 1,\n",
        "    \"ddqn_target_update_interval\": 100\n",
        "}\n",
        "\n",
        "q_func = chainerrl.q_functions.FCStateQFunctionWithDiscreteAction(\n",
        "    hyper_params[\"obs_size\"],\n",
        "    hyper_params[\"n_actions\"],\n",
        "    n_hidden_layers=hyper_params[\"n_hidden_layers\"],\n",
        "    n_hidden_channels=hyper_params[\"n_hidden_channels\"])\n",
        "q_func.to_gpu(0)\n",
        "\n",
        "optimizer = chainer.optimizers.Adam(eps=hyper_params[\"adam_eps\"])\n",
        "optimizer.setup(q_func)\n",
        "\n",
        "explorer = chainerrl.explorers.LinearDecayEpsilonGreedy(\n",
        "    start_epsilon=hyper_params[\"start_epsilon\"],\n",
        "    end_epsilon=hyper_params[\"end_epsilon\"],\n",
        "    decay_steps=hyper_params[\"decay_steps\"],\n",
        "    random_action_func=env.random_action\n",
        ")\n",
        "\n",
        "replay_buffer = chainerrl.replay_buffer.ReplayBuffer(capacity=hyper_params[\"replay_buffer_capacity\"])\n",
        "\n",
        "agent = chainerrl.agents.DoubleDQN(\n",
        "    q_func,\n",
        "    optimizer,\n",
        "    replay_buffer,\n",
        "    hyper_params[\"gamma\"],\n",
        "    explorer,\n",
        "    replay_start_size=hyper_params[\"ddqn_replay_start_size\"],\n",
        "    update_interval=hyper_params[\"ddqn_update_interval\"],\n",
        "    target_update_interval=hyper_params[\"ddqn_target_update_interval\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkVAapq5QbY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_episodes = 500\n",
        "\n",
        "for i in range(1, n_episodes + 1):\n",
        "  obs = env.reset()\n",
        "  reward = 0\n",
        "  done = False\n",
        "  R = 0\n",
        "  \n",
        "  while not done:\n",
        "    action = agent.act_and_train(obs, reward)\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    R += reward\n",
        "\n",
        "  agent.stop_episode_and_train(obs, reward, done)\n",
        "  \n",
        "  metrics = {\n",
        "      \"reward\": R,\n",
        "      \"epsilon\": agent.explorer.epsilon,\n",
        "      \"win\": env.win,\n",
        "      \"lose\": env.lose,\n",
        "      \"funds\": env.funds + env.buy_price\n",
        "  }\n",
        "  experiment.log_metrics(metrics, step=i)\n",
        "  \n",
        "  if i % 10 == 0:\n",
        "    print(\"episode:\", i, \", R:\", R, \", statistics:\", agent.get_statistics(), \", epsilon:\", agent.explorer.epsilon)\n",
        "    env.render()\n",
        "\n",
        "print(\"Finished.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLy9o0Z_Xdm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obs = env.reset()\n",
        "R = 0\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "  action = agent.act(obs)\n",
        "  obs, reward, done, _ = env.step(action)\n",
        "  \n",
        "  env.render()\n",
        "\n",
        "agent.stop_episode()\n",
        "\n",
        "df_result = env.df_action.query(\"7786 <= id\").copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF-0dcVEXe0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment.log_asset_data(df_result.to_csv(), file_name=\"result.csv\")\n",
        "\n",
        "df_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez-u5MH9Xfps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(20, 5))\n",
        "subplot = fig.add_subplot(111)\n",
        "subplot.plot(df_result[\"win\"], label=\"win\")\n",
        "subplot.plot(df_result[\"lose\"], label=\"lose\")\n",
        "subplot.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "experiment.log_figure(figure_name=\"win_vs_lose\", figure=fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuv5j6s9XgU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(20, 5))\n",
        "subplot = fig.add_subplot(222)\n",
        "subplot.plot(df_result[\"reward\"], label=\"reward\")\n",
        "subplot.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "experiment.log_figure(figure_name=\"reward\", figure=fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enLs69EwXhFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}