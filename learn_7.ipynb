{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learn.7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/u6k/ml-sandbox/blob/master/learn_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPj8ZzVI69E7",
        "colab_type": "text"
      },
      "source": [
        "未来株価を確実に取得できた場合、強化学習で効果的な利益を得られるか？それができないなら、未来株価を予測しても意味がないことになる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euO8AXq-b-TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0MjwqCERNyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install chainerrl comet_ml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_an2jlQL0UOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from comet_ml import Experiment\n",
        "\n",
        "experiment = Experiment(api_key=COMET_ML_API_KEY, project_name=\"learn-stocks.7\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMM9MGwZcF5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CSVを読み込む\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_csv = pd.read_csv(\"drive/My Drive/projects/ml_data/stocks/stock_prices.20190523.csv\")\n",
        "df_csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGxc2V0R2of_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df = df_csv.copy()\n",
        "\n",
        "df = df.query(\"ticker_symbol == '7974'\")\n",
        "df = df[[\"date\", \"opening_price\", \"high_price\", \"low_price\", \"close_price\", \"turnover\", \"adjustment_value\"]]\n",
        "df = df.sort_values(\"date\")\n",
        "df = df.drop_duplicates()\n",
        "df = df.assign(id=np.arange(len(df)))\n",
        "df = df.set_index(\"id\")\n",
        "\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP82V22o7Jdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.preprocessing as sp\n",
        "\n",
        "df_input = df[-300:].copy()\n",
        "\n",
        "price = df_input[\"opening_price\"].values\n",
        "price = np.append(price, df_input[\"close_price\"].values)\n",
        "price = np.array(price).reshape(len(price), 1)\n",
        "\n",
        "scaler = sp.MinMaxScaler()\n",
        "scaler.fit(price)\n",
        "\n",
        "opening_price = df_input[\"opening_price\"].values\n",
        "opening_price = np.array(opening_price).reshape(len(opening_price), 1)\n",
        "df_input[\"scaled_opening_price\"] = scaler.transform(opening_price)\n",
        "\n",
        "close_price = df_input[\"close_price\"].values\n",
        "close_price = np.array(close_price).reshape(len(close_price), 1)\n",
        "df_input[\"scaled_close_price\"] = scaler.transform(close_price)\n",
        "\n",
        "df_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTxEKL7tUvyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import gym\n",
        "import gym.spaces\n",
        "import numpy as np\n",
        "\n",
        "class LearnEnv(gym.Env):\n",
        "  def __init__(self, df, start_id, end_id):\n",
        "    self.DF = df_input.copy()\n",
        "    self.START_ID = start_id\n",
        "    self.END_ID = end_id\n",
        "\n",
        "    self.reset()\n",
        "    \n",
        "    self.data_len = self.END_ID - self.START_ID\n",
        "    self.action_size = 2 # 0...何もしない、1...購入or売却\n",
        "    self.observation_size = len(self.observe())\n",
        "    \n",
        "  def reset(self):\n",
        "    self.total_reward = 0.0\n",
        "    self.funds = 0.0\n",
        "    self.current_id = self.START_ID\n",
        "    self.buy_price = 0.0\n",
        "    self.done = False\n",
        "    self.win = 0\n",
        "    self.lose = 0\n",
        "    \n",
        "    self.df_action = self.DF.copy()\n",
        "    self.df_action = self.df_action.assign(reward=0.)\n",
        "    self.df_action = self.df_action.assign(funds=0.)\n",
        "    self.df_action = self.df_action.assign(buy=0)\n",
        "    self.df_action = self.df_action.assign(sell=0)\n",
        "    self.df_action = self.df_action.assign(win=0)\n",
        "    self.df_action = self.df_action.assign(lose=0)\n",
        "    \n",
        "    return self.observe()\n",
        "    \n",
        "  def step(self, action):\n",
        "    if action == 0:\n",
        "      reward = 0.0\n",
        "    elif self.buy_price == 0.0:\n",
        "      # buy\n",
        "      self.buy_price = self.df_action.at[self.current_id, \"scaled_opening_price\"]\n",
        "      self.funds -= self.buy_price\n",
        "      reward = 0.0\n",
        "      \n",
        "      self.df_action.at[self.current_id, \"buy\"] = 1\n",
        "    elif self.buy_price != 0.0:\n",
        "      # sell\n",
        "      sell_price = self.df_action.at[self.current_id, \"scaled_close_price\"]\n",
        "      self.funds += sell_price\n",
        "      reward = sell_price - self.buy_price\n",
        "      self.total_reward += reward\n",
        "      self.buy_price = 0.0\n",
        "      \n",
        "      if reward > 0:\n",
        "        self.win += 1\n",
        "      else:\n",
        "        self.lose += 1\n",
        "      \n",
        "      self.df_action.at[self.current_id, \"sell\"] = 1\n",
        "\n",
        "    self.df_action.at[self.current_id, \"reward\"] = self.total_reward\n",
        "    self.df_action.at[self.current_id, \"funds\"] = self.funds\n",
        "    self.df_action.at[self.current_id, \"win\"] = self.win\n",
        "    self.df_action.at[self.current_id, \"lose\"] = self.lose\n",
        "    \n",
        "    self.current_id += 1\n",
        "    if self.current_id >= self.END_ID:\n",
        "      self.done = True\n",
        "    \n",
        "    return self.observe(), reward, self.done, {}\n",
        "  \n",
        "  def render(self):\n",
        "    print(self.df_action.loc[self.current_id-1])\n",
        "  \n",
        "  def observe(self):\n",
        "    obs = np.array(\n",
        "        [self.df_action.at[self.current_id + i, \"scaled_opening_price\"] for i in range(-1, 2)],\n",
        "        dtype=np.float32\n",
        "    )\n",
        "    obs = np.append(obs, np.array(\n",
        "        [self.df_action.at[self.current_id + i, \"scaled_close_price\"] for i in range(-1, 2)],\n",
        "        dtype=np.float32\n",
        "    ))\n",
        "    obs = np.append(obs, np.array(self.buy_price, dtype=np.float32))\n",
        "\n",
        "    return obs\n",
        "  \n",
        "  def random_action(self):\n",
        "    return np.random.randint(0, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu2YTLxbhTm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = LearnEnv(df, 8036-250, 8036)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk_T4mcEfXsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer\n",
        "import chainerrl\n",
        "\n",
        "hyper_params = {\n",
        "    \"n_hidden_layers\": 3,\n",
        "    \"obs_size\": env.observation_size,\n",
        "    \"n_actions\": env.action_size,\n",
        "    \"n_hidden_channels\": env.observation_size * env.action_size,\n",
        "    \"adam_eps\": 1e-2,\n",
        "    \"gamma\": 0.95,\n",
        "    \"start_epsilon\": 1.0,\n",
        "    \"end_epsilon\": 0.3,\n",
        "    \"decay_steps\": 200 * env.data_len,\n",
        "    \"replay_buffer_capacity\": 10 ** 6,\n",
        "    \"ddqn_replay_start_size\": 500,\n",
        "    \"ddqn_update_interval\": 1,\n",
        "    \"ddqn_target_update_interval\": 100\n",
        "}\n",
        "\n",
        "q_func = chainerrl.q_functions.FCStateQFunctionWithDiscreteAction(\n",
        "    hyper_params[\"obs_size\"],\n",
        "    hyper_params[\"n_actions\"],\n",
        "    n_hidden_layers=hyper_params[\"n_hidden_layers\"],\n",
        "    n_hidden_channels=hyper_params[\"n_hidden_channels\"])\n",
        "q_func.to_gpu(0)\n",
        "\n",
        "optimizer = chainer.optimizers.Adam(eps=hyper_params[\"adam_eps\"])\n",
        "optimizer.setup(q_func)\n",
        "\n",
        "explorer = chainerrl.explorers.LinearDecayEpsilonGreedy(\n",
        "    start_epsilon=hyper_params[\"start_epsilon\"],\n",
        "    end_epsilon=hyper_params[\"end_epsilon\"],\n",
        "    decay_steps=hyper_params[\"decay_steps\"],\n",
        "    random_action_func=env.random_action\n",
        ")\n",
        "\n",
        "replay_buffer = chainerrl.replay_buffer.ReplayBuffer(capacity=hyper_params[\"replay_buffer_capacity\"])\n",
        "\n",
        "agent = chainerrl.agents.DoubleDQN(\n",
        "    q_func,\n",
        "    optimizer,\n",
        "    replay_buffer,\n",
        "    hyper_params[\"gamma\"],\n",
        "    explorer,\n",
        "    replay_start_size=hyper_params[\"ddqn_replay_start_size\"],\n",
        "    update_interval=hyper_params[\"ddqn_update_interval\"],\n",
        "    target_update_interval=hyper_params[\"ddqn_target_update_interval\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkVAapq5QbY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_episodes = 500\n",
        "\n",
        "for i in range(1, n_episodes + 1):\n",
        "  obs = env.reset()\n",
        "  reward = 0\n",
        "  done = False\n",
        "  R = 0\n",
        "  \n",
        "  while not done:\n",
        "    action = agent.act_and_train(obs, reward)\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    R += reward\n",
        "\n",
        "  agent.stop_episode_and_train(obs, reward, done)\n",
        "  \n",
        "  metrics = {\n",
        "      \"reward\": R,\n",
        "      \"epsilon\": agent.explorer.epsilon,\n",
        "      \"win\": env.win,\n",
        "      \"lose\": env.lose,\n",
        "      \"funds\": env.funds + env.buy_price\n",
        "  }\n",
        "  experiment.log_metrics(metrics, step=i)\n",
        "  \n",
        "  if i % 10 == 0:\n",
        "    print(\"episode:\", i, \", R:\", R, \", statistics:\", agent.get_statistics(), \", epsilon:\", agent.explorer.epsilon)\n",
        "    env.render()\n",
        "\n",
        "print(\"Finished.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP7NK3tyYsv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obs = env.reset()\n",
        "R = 0\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "  action = agent.act(obs)\n",
        "  obs, reward, done, _ = env.step(action)\n",
        "  \n",
        "  env.render()\n",
        "\n",
        "agent.stop_episode()\n",
        "\n",
        "df_result = env.df_action.query(\"7786 <= id\").copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70jcg6q8UAtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment.log_asset_data(df_result.to_csv(), file_name=\"result.csv\")\n",
        "\n",
        "df_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvZmCTgi_pT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(20, 5))\n",
        "subplot = fig.add_subplot(111)\n",
        "subplot.plot(df_result[\"win\"], label=\"win\")\n",
        "subplot.plot(df_result[\"lose\"], label=\"lose\")\n",
        "subplot.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "experiment.log_figure(figure_name=\"win_vs_lose\", figure=fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIa0-vrh_rt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(20, 5))\n",
        "subplot = fig.add_subplot(222)\n",
        "subplot.plot(df_result[\"reward\"], label=\"reward\")\n",
        "subplot.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "experiment.log_figure(figure_name=\"reward\", figure=fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XoCn-jb_xaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}