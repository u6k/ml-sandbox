{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learn.2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/u6k/ml-sandbox/blob/master/learn_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euO8AXq-b-TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0MjwqCERNyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install chainerrl comet_ml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMM9MGwZcF5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CSVを読み込む\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_csv = pd.read_csv(\"drive/My Drive/projects/ml_data/stocks/nikkei_averages.csv\")\n",
        "df_csv.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKN_laZxwdL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_csv.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5vQl1oPwie5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_csv.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa9TUjoTeSCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df = df_csv.copy()\n",
        "\n",
        "df = df[[\"date\", \"opening_price\", \"high_price\", \"low_price\", \"close_price\"]]\n",
        "df = df.sort_values(\"date\")\n",
        "df = df.drop_duplicates()\n",
        "df = df.assign(id=np.arange(len(df)))\n",
        "df = df.set_index(\"id\")\n",
        "\n",
        "df = df.assign(rate_of_return=df[\"close_price\"].pct_change())\n",
        "\n",
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDJ5EXTAeiBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBbdTOqYei7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTxEKL7tUvyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import gym\n",
        "import gym.spaces\n",
        "import numpy as np\n",
        "\n",
        "class LearnEnv():\n",
        "  def __init__(self, df, start_id, end_id):\n",
        "    self.DF = df.copy()\n",
        "    self.START_ID = start_id\n",
        "    self.END_ID = end_id\n",
        "\n",
        "    self.reset()\n",
        "    \n",
        "    self.data_len = self.END_ID - self.START_ID\n",
        "    self.action_size = 2 # 0...何もしない、1...購入or売却\n",
        "    self.observation_size = len(self.observe())\n",
        "    \n",
        "  def reset(self):\n",
        "    self.total_reward = 0.0\n",
        "    self.funds = 0.0\n",
        "    self.current_id = self.START_ID\n",
        "    self.buy_price = 0.0\n",
        "    self.done = False\n",
        "    self.win = 0\n",
        "    self.lose = 0\n",
        "    \n",
        "    self.df_action = self.DF.copy()\n",
        "    self.df_action = self.df_action.assign(reward=0.)\n",
        "    self.df_action = self.df_action.assign(funds=0.)\n",
        "    self.df_action = self.df_action.assign(buy=0)\n",
        "    self.df_action = self.df_action.assign(sell=0)\n",
        "    self.df_action = self.df_action.assign(win=0)\n",
        "    self.df_action = self.df_action.assign(lose=0)\n",
        "    \n",
        "    return self.observe()\n",
        "    \n",
        "  def step(self, action):\n",
        "    if action == 0:\n",
        "      reward = 0.0\n",
        "    elif self.buy_price == 0.0:\n",
        "      # buy\n",
        "      self.buy_price = self.df_action.at[self.current_id, \"opening_price\"]\n",
        "      self.funds -= self.buy_price\n",
        "      reward = 0.0\n",
        "      \n",
        "      self.df_action.at[self.current_id, \"buy\"] = 1\n",
        "    elif self.buy_price != 0.0:\n",
        "      # sell\n",
        "      sell_price = self.df_action.at[self.current_id, \"close_price\"]\n",
        "      self.funds += sell_price\n",
        "      reward = sell_price - self.buy_price\n",
        "      self.total_reward += reward\n",
        "      self.buy_price = 0.0\n",
        "      self.predict_buy_price = 0.0\n",
        "      \n",
        "      if reward > 0:\n",
        "        self.win += 1\n",
        "      else:\n",
        "        self.lose += 1\n",
        "      \n",
        "      self.df_action.at[self.current_id, \"sell\"] = 1\n",
        "    \n",
        "    self.df_action.at[self.current_id, \"reward\"] = self.total_reward\n",
        "    self.df_action.at[self.current_id, \"funds\"] = self.funds\n",
        "    self.df_action.at[self.current_id, \"win\"] = self.win\n",
        "    self.df_action.at[self.current_id, \"lose\"] = self.lose\n",
        "    \n",
        "    self.current_id += 1\n",
        "    if self.current_id >= self.END_ID:\n",
        "      self.done = True\n",
        "    \n",
        "    return self.observe(), reward, self.done, {}\n",
        "\n",
        "  def render(self):\n",
        "    print(self.df_action.loc[self.current_id-1])\n",
        "  \n",
        "  def observe(self):\n",
        "    obs = np.array(\n",
        "        [self.df_action.at[self.current_id - i, \"rate_of_return\"] for i in range(1, 6)],\n",
        "        dtype=np.float32\n",
        "    )\n",
        "    \n",
        "    return obs\n",
        "  \n",
        "  def random_action(self):\n",
        "    return np.random.randint(0, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu2YTLxbhTm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = LearnEnv(df, 19090-250, 19090)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIh4bRoXgBF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from comet_ml import Experiment\n",
        "\n",
        "experiment = Experiment(api_key=COMET_ML_API_KEY, project_name=\"learn-stocks.2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk_T4mcEfXsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer\n",
        "import chainerrl\n",
        "\n",
        "hyper_params = {\n",
        "    \"n_hidden_layers\": 3,\n",
        "    \"obs_size\": env.observation_size,\n",
        "    \"n_actions\": env.action_size,\n",
        "    \"n_hidden_channels\": env.observation_size * env.action_size,\n",
        "    \"adam_eps\": 1e-2,\n",
        "    \"gamma\": 0.95,\n",
        "    \"start_epsilon\": 1.0,\n",
        "    \"end_epsilon\": 0.3,\n",
        "    \"decay_steps\": 200 * 200,\n",
        "    \"replay_buffer_capacity\": 10 ** 6,\n",
        "    \"ddqn_replay_start_size\": 500,\n",
        "    \"ddqn_update_interval\": 1,\n",
        "    \"ddqn_target_update_interval\": 100\n",
        "}\n",
        "\n",
        "q_func = chainerrl.q_functions.FCStateQFunctionWithDiscreteAction(\n",
        "    hyper_params[\"obs_size\"],\n",
        "    hyper_params[\"n_actions\"],\n",
        "    n_hidden_layers=hyper_params[\"n_hidden_layers\"],\n",
        "    n_hidden_channels=hyper_params[\"n_hidden_channels\"])\n",
        "q_func.to_gpu(0)\n",
        "\n",
        "optimizer = chainer.optimizers.Adam(eps=hyper_params[\"adam_eps\"])\n",
        "optimizer.setup(q_func)\n",
        "\n",
        "explorer = chainerrl.explorers.LinearDecayEpsilonGreedy(\n",
        "    start_epsilon=hyper_params[\"start_epsilon\"],\n",
        "    end_epsilon=hyper_params[\"end_epsilon\"],\n",
        "    decay_steps=hyper_params[\"decay_steps\"],\n",
        "    random_action_func=env.random_action\n",
        ")\n",
        "\n",
        "replay_buffer = chainerrl.replay_buffer.ReplayBuffer(capacity=hyper_params[\"replay_buffer_capacity\"])\n",
        "\n",
        "agent = chainerrl.agents.DoubleDQN(\n",
        "    q_func,\n",
        "    optimizer,\n",
        "    replay_buffer,\n",
        "    hyper_params[\"gamma\"],\n",
        "    explorer,\n",
        "    replay_start_size=hyper_params[\"ddqn_replay_start_size\"],\n",
        "    update_interval=hyper_params[\"ddqn_update_interval\"],\n",
        "    target_update_interval=hyper_params[\"ddqn_target_update_interval\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkVAapq5QbY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_episodes = 500\n",
        "\n",
        "for i in range(1, n_episodes + 1):\n",
        "  obs = env.reset()\n",
        "  reward = 0\n",
        "  done = False\n",
        "  R = 0\n",
        "  \n",
        "  while not done:\n",
        "    action = agent.act_and_train(obs, reward)\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    R += reward\n",
        "\n",
        "  agent.stop_episode_and_train(obs, reward, done)\n",
        "  \n",
        "  metrics = {\n",
        "      \"reward\": R,\n",
        "      \"epsilon\": agent.explorer.epsilon,\n",
        "      \"win\": env.win,\n",
        "      \"lose\": env.lose,\n",
        "      \"funds\": env.funds + env.buy_price\n",
        "  }\n",
        "  experiment.log_metrics(metrics, step=i)\n",
        "  \n",
        "  if i % 10 == 0:\n",
        "    print(\"episode:\", i, \", R:\", R, \", statistics:\", agent.get_statistics(), \", epsilon:\", agent.explorer.epsilon)\n",
        "    env.render()\n",
        "\n",
        "print(\"Finished.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EZnKVuKfjrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obs = env.reset()\n",
        "R = 0\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "  action = agent.act(obs)\n",
        "  obs, reward, done, _ = env.step(action)\n",
        "  \n",
        "  env.render()\n",
        "\n",
        "agent.stop_episode()\n",
        "\n",
        "df_result = env.df_action.query(\"18840 <= id <= 19090\").copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1JHNbEXgyFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment.log_asset_data(df_result.to_csv(), file_name=\"result.csv\")\n",
        "\n",
        "df_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjpz4X36g-PW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(20, 5))\n",
        "subplot = fig.add_subplot(111)\n",
        "subplot.plot(df_result[\"win\"], label=\"win\")\n",
        "subplot.plot(df_result[\"lose\"], label=\"lose\")\n",
        "subplot.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "experiment.log_figure(figure_name=\"win_vs_lose\", figure=fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1lf3QqmnfYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(20, 5))\n",
        "subplot = fig.add_subplot(222)\n",
        "subplot.plot(df_result[\"reward\"], label=\"reward\")\n",
        "subplot.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "experiment.log_figure(figure_name=\"reward\", figure=fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fxUnjQNhIlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}